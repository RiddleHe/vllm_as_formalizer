{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "19b47910",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import json, re\n",
    "from collections import defaultdict, OrderedDict\n",
    "from statistics import mean, stdev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "75bc7e28",
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_DIR = Path(\"/home/mh3897/vllm_as_formalizer/results/precision_recall\")\n",
    "OUTPUT_DIR = Path(\"/home/mh3897/vllm_as_formalizer/results/findings\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "158606bd",
   "metadata": {},
   "source": [
    "## Main table: success rate across methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "378fc03c",
   "metadata": {},
   "outputs": [],
   "source": [
    "MULTI_RUN_DATASETS = {\"blocksworld-small\", \"cooking-small\"}\n",
    "METRIC_KEYS = [\n",
    "    \"simulation_success_rate\",\n",
    "    \"plan_success_rate\",\n",
    "    \"compilation_success_rate\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "53d68688",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_metrics_from_file(path):\n",
    "    with path.open(\"r\") as f:\n",
    "        data = json.load(f)\n",
    "    summary = data.get(\"summary\", {})\n",
    "    counts = summary.get(\"counts\", {})\n",
    "\n",
    "    tasks_total = summary.get(\"tasks_total\", 0)\n",
    "    successes = summary.get(\"successes\", 0)\n",
    "    tasks_with_plan = summary.get(\"tasks_with_plan\", 0)\n",
    "    parse_errors = counts.get(\"task_with_parse_error\", 0)\n",
    "\n",
    "    if not tasks_total:\n",
    "        return {k: float(\"nan\") for k in METRIC_KEYS}\n",
    "\n",
    "    return {\n",
    "        \"simulation_success_rate\": successes / tasks_total,\n",
    "        \"plan_success_rate\": tasks_with_plan / tasks_total,\n",
    "        \"compilation_success_rate\": (tasks_total - parse_errors) / tasks_total,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f0eed5c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_filename(path):\n",
    "    parts = path.stem.split(\"-\")\n",
    "    \n",
    "    if parts[0] == \"gpt\" and parts[1].startswith(\"4.\"):\n",
    "        model = \"-\".join(parts[:2])\n",
    "        rest = parts[2:]\n",
    "    else:\n",
    "        model = parts[0]\n",
    "        rest = parts[1:]\n",
    "    \n",
    "    if rest[0] in {\"blocksworld\", \"cooking\"}:\n",
    "        dataset = \"-\".join(rest[:2])\n",
    "        rest = rest[2:]\n",
    "    else:\n",
    "        dataset = rest[0]\n",
    "        rest = rest[1:]\n",
    "\n",
    "    run = None\n",
    "    if rest and rest[-1].isdigit() and len(rest) >= 2 and rest[-2] == \"run\":\n",
    "        run = int(rest[-1])\n",
    "        rest = rest[:-2]\n",
    "    \n",
    "    pipeline = \"-\".join(rest)\n",
    "\n",
    "    return model, dataset, pipeline, run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "351e234b",
   "metadata": {},
   "outputs": [],
   "source": [
    "runs_by = defaultdict(lambda: defaultdict(lambda: defaultdict(list)))\n",
    "\n",
    "for path in sorted(BASE_DIR.glob(\"*.json\")):\n",
    "    try:\n",
    "        model, dataset, pipeline, run = parse_filename(path)\n",
    "    except Exception:\n",
    "        continue\n",
    "    runs_by[model][dataset][pipeline].append(load_metrics_from_file(path))\n",
    "\n",
    "def mean_of_list(dlist, key):\n",
    "    return mean(d[key] for d in dlist)\n",
    "\n",
    "def std_of_list(dlist, key):\n",
    "    vals = [d[key] for d in dlist]\n",
    "    return stdev(vals) if len(vals) > 1 else 0\n",
    "\n",
    "result = defaultdict(dict)\n",
    "\n",
    "for model, ds_map in runs_by.items():\n",
    "    for dataset, pipeline_map in ds_map.items():\n",
    "        for pipeline, runs in pipeline_map.items():\n",
    "            mean_metrics = {k: mean_of_list(runs, k) for k in METRIC_KEYS}\n",
    "            ds_entry = {\"mean\": mean_metrics}\n",
    "\n",
    "            if dataset in MULTI_RUN_DATASETS and len(runs) > 1:\n",
    "                std_metrics = {k: std_of_list(runs, k) for k in METRIC_KEYS}\n",
    "                ds_entry[\"std\"] = std_metrics\n",
    "\n",
    "            result[model].setdefault(dataset, {})[pipeline] = ds_entry    \n",
    "\n",
    "def round_nested(obj, ndigits=4):\n",
    "    if isinstance(obj, dict):\n",
    "        return {k: round_nested(v, ndigits) for k, v in obj.items()}\n",
    "    if isinstance(obj, list):\n",
    "        return [round_nested(v, ndigits) for v in obj]\n",
    "    if isinstance(obj, float):\n",
    "        return round(obj, ndigits)\n",
    "    return obj\n",
    "\n",
    "result_rounded = round_nested(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e00d5cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "OUTPUT_PATH = OUTPUT_DIR / \"success_rates.json\"\n",
    "with OUTPUT_PATH.open(\"w\") as f:\n",
    "    json.dump(result_rounded, f, indent=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97c299ba",
   "metadata": {},
   "source": [
    "## Table for precision and recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e98af512",
   "metadata": {},
   "outputs": [],
   "source": [
    "SECTIONS = (\"objects\", \"init\", \"goal\")\n",
    "SKIP_PIPELINES = {\"direct-plan\"}\n",
    "dataset_weights = {\"alfred\": 150, \"blocksworld-small\": 10, \"cooking-small\": 10, \"blocksworld-real\": 102}\n",
    "TOTAL_WEIGHT = sum(dataset_weights.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "66fc3ad3",
   "metadata": {},
   "outputs": [],
   "source": [
    "per_run = defaultdict(list)\n",
    "\n",
    "for path in sorted(BASE_DIR.glob(\"*.json\")):\n",
    "    model, dataset, pipeline, run = parse_filename(path)\n",
    "    if pipeline in SKIP_PIPELINES:\n",
    "        continue\n",
    "    with path.open() as f:\n",
    "        data = json.load(f)\n",
    "\n",
    "    by_section = data.get(\"summary\", {}).get(\"by_section\", {})\n",
    "    for s in SECTIONS:\n",
    "        sec = by_section.get(s, {})\n",
    "        p = float(sec.get(\"macro_precision\", 0.0))\n",
    "        r = float(sec.get(\"macro_recall\", 0.0))\n",
    "        \n",
    "        per_run[(model, pipeline, dataset, s)].append((float(p), float(r)))\n",
    "\n",
    "per_ds = {}\n",
    "\n",
    "for key, pr_list in per_run.items():\n",
    "    model, pipe, ds, sec = key\n",
    "    ps = [p for p, _ in pr_list]\n",
    "    rs = [r for _, r in pr_list]\n",
    "    per_ds[key] = (mean(ps) if ps else 0.0, mean(rs) if rs else 0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6518e2a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def f1_from_pr(p, r):\n",
    "    return (2*p*r / (p+r)) if (p+r) else 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0506fde9",
   "metadata": {},
   "outputs": [],
   "source": [
    "per_model_pipe = defaultdict(\n",
    "    lambda: {s: {\"precisions\": [], 'recalls': [], 'weights': []} for s in SECTIONS}\n",
    ")\n",
    "\n",
    "for (model, pipeline, dataset, section), (p, r) in per_ds.items():\n",
    "    d = per_model_pipe[model, pipeline][section]\n",
    "    d['precisions'].append(p)\n",
    "    d['recalls'].append(r)\n",
    "    d['weights'].append(dataset_weights[dataset])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f99ea36d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def wmean(values, weights, denom):\n",
    "    num = sum(v * w for v, w in zip(values, weights))\n",
    "    return (num / denom) if denom else 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "159d6d4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_macro = {}\n",
    "\n",
    "for (model, pipe), sec_vals in per_model_pipe.items():\n",
    "    result_macro.setdefault(model, {})\n",
    "    result_macro[model].setdefault(pipe, {})\n",
    "    for s in SECTIONS:\n",
    "        P = sec_vals[s]['precisions']\n",
    "        R = sec_vals[s]['recalls']\n",
    "        W = sec_vals[s]['weights']\n",
    "        \n",
    "        avg_p = wmean(P, W, sum(W))\n",
    "        avg_r = wmean(R, W, sum(W))\n",
    "        avg_f1 = f1_from_pr(avg_p, avg_r)\n",
    "\n",
    "        result_macro[model][pipe][s] = {\n",
    "            \"precision\": avg_p,\n",
    "            \"recall\": avg_r,\n",
    "            \"f1\": avg_f1,\n",
    "        }\n",
    "\n",
    "result_macro_rounded = round_nested(result_macro)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e35a9bdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "OUTPUT_PATH_PR = OUTPUT_DIR / \"precision_recall.json\"\n",
    "with OUTPUT_PATH_PR.open(\"w\") as f:\n",
    "    json.dump(result_macro_rounded, f, indent=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fecb0723",
   "metadata": {},
   "source": [
    "## Token utilization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9e8a4d35",
   "metadata": {},
   "outputs": [],
   "source": [
    "TOKEN_PATH = Path(\"/home/mh3897/vllm_as_formalizer/results/tokens/tokens_all_runs.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "31de9919",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_json(path):\n",
    "    with open(path, \"r\", encoding=\"utf-8\") as f:\n",
    "        return json.load(f)\n",
    "\n",
    "def mean_of_list(dlist, key):\n",
    "    return mean(d[key] for d in dlist)\n",
    "\n",
    "def round_nested(obj, ndigits=4):\n",
    "    if isinstance(obj, dict):\n",
    "        return {k: round_nested(v, ndigits) for k, v in obj.items()}\n",
    "    if isinstance(obj, list):\n",
    "        return [round_nested(v, ndigits) for v in obj]\n",
    "    if isinstance(obj, float):\n",
    "        return round(obj, ndigits)\n",
    "    return obj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "89ffac78",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "from statistics import mode\n",
    "\n",
    "per_run = defaultdict(list)\n",
    "token_json = read_json(TOKEN_PATH)\n",
    "\n",
    "for e in token_json:\n",
    "    key = (e[\"model_name\"], e[\"dataset\"], e[\"pipeline\"])\n",
    "    per_run[key].append(e)\n",
    "\n",
    "def weighted_avg(runs, field, wfield=\"n_tasks\"):\n",
    "    num = sum(r[field] * r[wfield] for r in runs)\n",
    "    den = sum(r[wfield] for r in runs)\n",
    "    return (num / den) if den else 0.0\n",
    "\n",
    "per_run_mean = {}\n",
    "for key, runs in per_run.items():\n",
    "    # Avg metric across runs (weighted by run n_tasks in case coverage differs)\n",
    "    p_avg = weighted_avg(runs, \"prompt_tokens_average\")\n",
    "    r_avg = weighted_avg(runs, \"response_tokens_average\")\n",
    "    t_avg = weighted_avg(runs, \"total_tokens_average\")\n",
    "\n",
    "    # Use ONE dataset weight, not sum over runs (avoid double-counting)\n",
    "    # Pick a robust representative (assert all equal; else use mode or max)\n",
    "    n_tasks_vals = [r[\"n_tasks\"] for r in runs]\n",
    "    dataset_tasks = mode(n_tasks_vals) if len(set(n_tasks_vals)) > 1 else n_tasks_vals[0]\n",
    "\n",
    "    per_run_mean[key] = {\n",
    "        \"prompt_tokens_average\": p_avg,\n",
    "        \"response_tokens_average\": r_avg,\n",
    "        \"total_tokens_average\": t_avg,\n",
    "        \"dataset_tasks\": dataset_tasks,  # weight used ONCE per dataset\n",
    "    }\n",
    "\n",
    "# Roll up to (model, pipeline) using dataset weight once\n",
    "per_model_pipe_accum = defaultdict(lambda: {\n",
    "    \"prompt_num\": 0.0, \"response_num\": 0.0, \"total_num\": 0.0, \"den\": 0.0\n",
    "})\n",
    "\n",
    "for (model, dataset, pipeline), stats in per_run_mean.items():\n",
    "    w = stats[\"dataset_tasks\"]\n",
    "    acc = per_model_pipe_accum[(model, pipeline)]\n",
    "    acc[\"prompt_num\"]   += stats[\"prompt_tokens_average\"]   * w\n",
    "    acc[\"response_num\"] += stats[\"response_tokens_average\"] * w\n",
    "    acc[\"total_num\"]    += stats[\"total_tokens_average\"]    * w\n",
    "    acc[\"den\"]          += w\n",
    "\n",
    "per_model_pipe_mean = {}\n",
    "for key, acc in per_model_pipe_accum.items():\n",
    "    den = acc[\"den\"] or 1.0\n",
    "    per_model_pipe_mean[key] = {\n",
    "        \"prompt_tokens_average\":   round_nested(acc[\"prompt_num\"]   / den, 4),\n",
    "        \"response_tokens_average\": round_nested(acc[\"response_num\"] / den, 4),\n",
    "        \"total_tokens_average\":    round_nested(acc[\"total_num\"]    / den, 4),\n",
    "        \"n_tasks_sum\": den,\n",
    "    }\n",
    "\n",
    "per_model = defaultdict(lambda: defaultdict(lambda: {\n",
    "    \"prompt_tokens_average\": 0.0,\n",
    "    \"response_tokens_average\": 0.0,\n",
    "    \"total_tokens_average\": 0.0,\n",
    "    \"n_tasks_sum\": 0.0,\n",
    "}))\n",
    "\n",
    "for (model, pipeline), counts in per_model_pipe_mean.items():\n",
    "    per_model[model][pipeline] = counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "01e458ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_sim_success_weighted(success, dataset_weights):\n",
    "    out = defaultdict(dict)\n",
    "    for model, ds_map in success.items():\n",
    "        num = defaultdict(float)\n",
    "        den = defaultdict(float)\n",
    "        for dataset, pipe_map in ds_map.items():\n",
    "            w = float(dataset_weights.get(dataset, 0))\n",
    "            for pipeline, d in pipe_map.items():\n",
    "                sim = d.get(\"mean\", {}).get(\"simulation_success_rate\")\n",
    "                if sim is None:\n",
    "                    continue\n",
    "\n",
    "                num[pipeline] += sim * w\n",
    "                den[pipeline] += w\n",
    "        for pipeline in num:\n",
    "            out[model][pipeline] = round_nested(num[pipeline] / den[pipeline], 4) if den[pipeline] else 0.0\n",
    "\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "e9280505",
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_sim_into_tokens(per_model, sim_avg):\n",
    "    merged = defaultdict(lambda: defaultdict(dict))\n",
    "    for model, pipes in per_model.items():\n",
    "        for pipeline, metrics in pipes.items():\n",
    "            merged[model][pipeline] = dict(metrics)\n",
    "            sim = sim_avg.get(model, {}).get(pipeline)\n",
    "            if sim is not None:\n",
    "                merged[model][pipeline][\"simulation_success_rate_average\"] = sim\n",
    "                tta = merged[model][pipeline].get(\"total_tokens_average\", 0.0) or 0.0\n",
    "                merged[model][pipeline][\"simulation_success_rate_average_per_total_tokens_average\"] = (\n",
    "                    round_nested(sim / tta if tta else 0.0, 6)\n",
    "                )\n",
    "    return merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "8fd57bb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_weights = {\"alfred\": 150, \"blocksworld-small\": 10, \"cooking-small\": 10, \"blocksworld-real\": 10, \"cooking-real\": 102}\n",
    "success = read_json(\"/home/mh3897/vllm_as_formalizer/results/findings/success_rates.json\")\n",
    "\n",
    "sim_avg_by_model_pipeline = compute_sim_success_weighted(success, dataset_weights)\n",
    "merged = merge_sim_into_tokens(per_model, sim_avg_by_model_pipeline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "a5bc7bc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "OUTPUT_DIR = Path(\"/home/mh3897/vllm_as_formalizer/results/findings\")\n",
    "OUTPUT_PATH_TOK = OUTPUT_DIR / \"success_rates_per_token.json\"\n",
    "with OUTPUT_PATH_TOK.open(\"w\") as f:\n",
    "    json.dump(merged, f, indent=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "82bd3279",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>Section</th>\n",
       "      <th colspan=\"3\" halign=\"left\">goal</th>\n",
       "      <th colspan=\"3\" halign=\"left\">init</th>\n",
       "      <th colspan=\"3\" halign=\"left\">objects</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>F1</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Model</th>\n",
       "      <th>Pipeline</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">gpt-4.1</th>\n",
       "      <th>caption</th>\n",
       "      <td>0.6844</td>\n",
       "      <td>0.7681</td>\n",
       "      <td>0.6171</td>\n",
       "      <td>0.6684</td>\n",
       "      <td>0.8783</td>\n",
       "      <td>0.5395</td>\n",
       "      <td>0.7875</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.6495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>direct-pddl</th>\n",
       "      <td>0.6464</td>\n",
       "      <td>0.7809</td>\n",
       "      <td>0.5514</td>\n",
       "      <td>0.5922</td>\n",
       "      <td>0.8635</td>\n",
       "      <td>0.4506</td>\n",
       "      <td>0.7234</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.5667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>scene-graph</th>\n",
       "      <td>0.7360</td>\n",
       "      <td>0.7944</td>\n",
       "      <td>0.6856</td>\n",
       "      <td>0.6799</td>\n",
       "      <td>0.8409</td>\n",
       "      <td>0.5706</td>\n",
       "      <td>0.8307</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.7104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>scene-graph-multi-step-batch</th>\n",
       "      <td>0.6449</td>\n",
       "      <td>0.7670</td>\n",
       "      <td>0.5563</td>\n",
       "      <td>0.5972</td>\n",
       "      <td>0.8803</td>\n",
       "      <td>0.4519</td>\n",
       "      <td>0.7144</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.5557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>scene-graph-multi-step-no-batch</th>\n",
       "      <td>0.6315</td>\n",
       "      <td>0.7526</td>\n",
       "      <td>0.5439</td>\n",
       "      <td>0.5841</td>\n",
       "      <td>0.8465</td>\n",
       "      <td>0.4459</td>\n",
       "      <td>0.7089</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.5491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">qwenvl</th>\n",
       "      <th>caption</th>\n",
       "      <td>0.5937</td>\n",
       "      <td>0.8755</td>\n",
       "      <td>0.4492</td>\n",
       "      <td>0.5062</td>\n",
       "      <td>0.8394</td>\n",
       "      <td>0.3624</td>\n",
       "      <td>0.6502</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.4817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>direct-pddl</th>\n",
       "      <td>0.4862</td>\n",
       "      <td>0.9444</td>\n",
       "      <td>0.3274</td>\n",
       "      <td>0.3328</td>\n",
       "      <td>0.8244</td>\n",
       "      <td>0.2085</td>\n",
       "      <td>0.4931</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.3273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>scene-graph</th>\n",
       "      <td>0.6263</td>\n",
       "      <td>0.9242</td>\n",
       "      <td>0.4736</td>\n",
       "      <td>0.5199</td>\n",
       "      <td>0.8311</td>\n",
       "      <td>0.3783</td>\n",
       "      <td>0.6531</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.4849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>scene-graph-multi-step-batch</th>\n",
       "      <td>0.4020</td>\n",
       "      <td>0.6308</td>\n",
       "      <td>0.2950</td>\n",
       "      <td>0.3666</td>\n",
       "      <td>0.6571</td>\n",
       "      <td>0.2542</td>\n",
       "      <td>0.4443</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.3156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>scene-graph-multi-step-no-batch</th>\n",
       "      <td>0.3893</td>\n",
       "      <td>0.6578</td>\n",
       "      <td>0.2765</td>\n",
       "      <td>0.3216</td>\n",
       "      <td>0.6151</td>\n",
       "      <td>0.2177</td>\n",
       "      <td>0.4107</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.2828</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Section                                    goal                      init  \\\n",
       "                                             F1 Precision  Recall      F1   \n",
       "Model   Pipeline                                                            \n",
       "gpt-4.1 caption                          0.6844    0.7681  0.6171  0.6684   \n",
       "        direct-pddl                      0.6464    0.7809  0.5514  0.5922   \n",
       "        scene-graph                      0.7360    0.7944  0.6856  0.6799   \n",
       "        scene-graph-multi-step-batch     0.6449    0.7670  0.5563  0.5972   \n",
       "        scene-graph-multi-step-no-batch  0.6315    0.7526  0.5439  0.5841   \n",
       "qwenvl  caption                          0.5937    0.8755  0.4492  0.5062   \n",
       "        direct-pddl                      0.4862    0.9444  0.3274  0.3328   \n",
       "        scene-graph                      0.6263    0.9242  0.4736  0.5199   \n",
       "        scene-graph-multi-step-batch     0.4020    0.6308  0.2950  0.3666   \n",
       "        scene-graph-multi-step-no-batch  0.3893    0.6578  0.2765  0.3216   \n",
       "\n",
       "Section                                                   objects            \\\n",
       "                                        Precision  Recall      F1 Precision   \n",
       "Model   Pipeline                                                              \n",
       "gpt-4.1 caption                            0.8783  0.5395  0.7875      1.00   \n",
       "        direct-pddl                        0.8635  0.4506  0.7234      1.00   \n",
       "        scene-graph                        0.8409  0.5706  0.8307      1.00   \n",
       "        scene-graph-multi-step-batch       0.8803  0.4519  0.7144      1.00   \n",
       "        scene-graph-multi-step-no-batch    0.8465  0.4459  0.7089      1.00   \n",
       "qwenvl  caption                            0.8394  0.3624  0.6502      1.00   \n",
       "        direct-pddl                        0.8244  0.2085  0.4931      1.00   \n",
       "        scene-graph                        0.8311  0.3783  0.6531      1.00   \n",
       "        scene-graph-multi-step-batch       0.6571  0.2542  0.4443      0.75   \n",
       "        scene-graph-multi-step-no-batch    0.6151  0.2177  0.4107      0.75   \n",
       "\n",
       "Section                                          \n",
       "                                         Recall  \n",
       "Model   Pipeline                                 \n",
       "gpt-4.1 caption                          0.6495  \n",
       "        direct-pddl                      0.5667  \n",
       "        scene-graph                      0.7104  \n",
       "        scene-graph-multi-step-batch     0.5557  \n",
       "        scene-graph-multi-step-no-batch  0.5491  \n",
       "qwenvl  caption                          0.4817  \n",
       "        direct-pddl                      0.3273  \n",
       "        scene-graph                      0.4849  \n",
       "        scene-graph-multi-step-batch     0.3156  \n",
       "        scene-graph-multi-step-no-batch  0.2828  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "p_r_dict = read_json(\"/home/mh3897/vllm_as_formalizer/results/findings/precision_recall.json\")\n",
    "\n",
    "rows = []\n",
    "for model, pipelines in p_r_dict.items():\n",
    "    for pipeline, metrics in pipelines.items():\n",
    "        for stage, values in metrics.items():\n",
    "            rows.append([\n",
    "                model, pipeline,\n",
    "                stage, values[\"precision\"], values[\"recall\"], values[\"f1\"]\n",
    "            ])\n",
    "\n",
    "p_r_df = pd.DataFrame(rows, columns=[\"Model\", \"Pipeline\", \"Section\", \"Precision\", \"Recall\", \"F1\"])\n",
    "p_r_df.set_index([\"Model\", \"Pipeline\", \"Section\"], inplace=True)\n",
    "\n",
    "p_r_df_wide = (\n",
    "    p_r_df.unstack(\"Section\").swaplevel(0, 1, axis=1).sort_index(axis=1, level=[0, 1])\n",
    ")\n",
    "\n",
    "p_r_df_wide"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43cd711e",
   "metadata": {},
   "source": [
    "## Violin graph on plan length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "32c4c011",
   "metadata": {},
   "outputs": [],
   "source": [
    "ROOT = Path(\"/home/mh3897/vllm_as_formalizer/results/success_rates\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "395c1826",
   "metadata": {},
   "outputs": [],
   "source": [
    "MULTI_RUN_DATASETS = {\"blocksworld-small\", \"cooking-small\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "820d667f",
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped = defaultdict(lambda: defaultdict(list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8f8d5591",
   "metadata": {},
   "outputs": [],
   "source": [
    "for p in sorted(ROOT.glob(\"*.json\")):\n",
    "    with open(p, \"r\") as f:\n",
    "        data = json.load(f)\n",
    "    model, dataset, pipeline, run = parse_filename(p)\n",
    "\n",
    "    sr = data[\"summary\"][\"success_rate\"]\n",
    "    \n",
    "    gt_lengths = set()\n",
    "    pred_lengths = set()\n",
    "\n",
    "    for t in data[\"tasks\"]:\n",
    "        ts = t.get(\"total_steps\", None)\n",
    "        pl = t.get(\"plan_len\", None)\n",
    "        if pl is not None and ts is not None:\n",
    "            gt_lengths.add(ts)\n",
    "            pred_lengths.add(pl)\n",
    "\n",
    "    grouped[(model, dataset)][pipeline].append(\n",
    "        {\n",
    "            \"run\": run,\n",
    "            \"success_rate\": float(sr),\n",
    "            \"gt_lengths\": gt_lengths,\n",
    "            \"pred_lengths\": pred_lengths,\n",
    "        }\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "63fb0768",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = {}\n",
    "\n",
    "for (model, dataset), pipelines in grouped.items():\n",
    "    is_multi = dataset in MULTI_RUN_DATASETS\n",
    "\n",
    "    candidates = []\n",
    "    for pipeline, runs in pipelines.items():\n",
    "        if is_multi:\n",
    "            avg_sr = mean([r['success_rate'] for r in runs]) if runs else 0.0\n",
    "            union_gt = set().union(*[r[\"gt_lengths\"] for r in runs]) if runs else set()\n",
    "            union_pred = set().union(*[r['pred_lengths'] for r in runs]) if runs else set()\n",
    "            candidates.append((avg_sr, pipeline, union_gt, union_pred))\n",
    "\n",
    "        else:\n",
    "            best_run = max(\n",
    "                runs,\n",
    "                key=lambda r: (r['success_rate'], -(len(r['gt_lengths']) + len(r['pred_lengths'])))\n",
    "            )\n",
    "            candidates.append((best_run['success_rate'], pipeline, best_run['gt_lengths'], best_run['pred_lengths']))\n",
    "\n",
    "    candidates.sort(key=lambda x: (-x[0], x[1]))\n",
    "    best_sr, best_pipeline, gt_set, pred_set = candidates[0]\n",
    "\n",
    "    results.setdefault(model, {})[dataset] = {\n",
    "        \"pipeline\": best_pipeline,\n",
    "        \"success_rate\": best_sr,\n",
    "        \"gt_lengths\": sorted(gt_set),\n",
    "        \"pred_lengths\": sorted(pred_set),\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9b534cb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_path_plan = \"/home/mh3897/vllm_as_formalizer/results/findings/plan_lengths.json\"\n",
    "with open(output_path_plan, \"w\") as f:\n",
    "    json.dump(results, f, indent=2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "villain",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
